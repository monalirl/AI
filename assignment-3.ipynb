{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method One\n",
    "import openai\n",
    "\n",
    "openai.api_key = 'openai_api_key' \n",
    "def generate_hinglish_translation(input_text):\n",
    "    prompt = f\"Translate the following English text to natural-sounding Hinglish :\\n\\\"{input_text}\\\"\\nOutput:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.9,\n",
    "        stop=None\n",
    "    )\n",
    "    hinglish_translation = response.choices[0].text.strip()\n",
    "    return hinglish_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1: Definitely share your feedback in the comment section.\n",
      "Output 1: \"Apni feedback jaroor comment section me share kijiye.\"\n",
      "\n",
      "Input 2: So even if it's a big video, I will clearly mention all the products.\n",
      "Output 2: \"Aisa bhi ho sakta hai ki agar yeh badi video ho toh main sabhi products ko clearly mention karunga.\"\n",
      "\n",
      "Input 3: I was waiting for my.\n",
      "Output 3: Main thha intezaar kar raha tha.\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "input_text_1 = \"Definitely share your feedback in the comment section.\"\n",
    "input_text_2 = \"So even if it's a big video, I will clearly mention all the products.\"\n",
    "input_text_3 = \"I was waiting for my.\"\n",
    "\n",
    "output_1 = generate_hinglish_translation(input_text_1)\n",
    "output_2 = generate_hinglish_translation(input_text_2)\n",
    "output_3 = generate_hinglish_translation(input_text_3)\n",
    "\n",
    "print(\"Input 1:\", input_text_1)\n",
    "print(\"Output 1:\", output_1)\n",
    "print(\"\\nInput 2:\", input_text_2)\n",
    "print(\"Output 2:\", output_2)\n",
    "print(\"\\nInput 3:\", input_text_3)\n",
    "print(\"Output 3:\", output_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English Text: Definitely share your feedback in the comment section.\n",
      "Translated Hinglish Text: टिप्पणी खण्ड में अपनी प्रतिक्रिया को निश्चित रूप से साझा करें.\n",
      "\n",
      "Original English Text: So even if it's a big video, I will clearly mention all the products.\n",
      "Translated Hinglish Text: तो यह एक बड़ा वीडियो है, तो भी मैं स्पष्ट रूप से सभी उत्पादों का उल्लेख करेंगे।\n",
      "\n",
      "Original English Text: I was waiting for my bag.\n",
      "Translated Hinglish Text: मैं अपने बैग के लिए इंतजार कर रहा था.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method 2\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate_to_hinglish(english_texts):\n",
    "    # Loading the model from HF\n",
    "    model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    translated_texts = []\n",
    "\n",
    "    for english_text in english_texts:\n",
    "        \n",
    "        inputs = tokenizer.encode(english_text, return_tensors=\"pt\")\n",
    "\n",
    "        \n",
    "        translated_ids = model.generate(inputs, max_length=128, num_beams=4, early_stopping=True)\n",
    "        translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        translated_texts.append(translated_text)\n",
    "\n",
    "    return translated_texts\n",
    "\n",
    "\n",
    "english_texts = [\"Definitely share your feedback in the comment section.\",\"So even if it's a big video, I will clearly mention all the products.\", \"I was waiting for my bag.\"]\n",
    "\n",
    "translated_hinglish_texts = translate_to_hinglish(english_texts)\n",
    "\n",
    "for eng, hin in zip(english_texts, translated_hinglish_texts):\n",
    "    print(\"Original English Text:\", eng)\n",
    "    print(\"Translated Hinglish Text:\", hin)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
